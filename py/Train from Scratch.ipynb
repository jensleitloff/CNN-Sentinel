{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for 05_train_ms_from_scratch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from keras.applications.vgg16 import VGG16 as VGG\n",
    "from keras.applications.densenet import DenseNet201 as DenseNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from image_functions import simple_image_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Change path to datasets and model here:<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define path to training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "path_to_split_datasets = \"~/Documents/Data/PyCon/AllBands\"\n",
    "use_vgg = False\n",
    "batch_size = 64\n",
    "\n",
    "# contruct path\n",
    "path_to_home = os.path.expanduser(\"~\")\n",
    "path_to_split_datasets = path_to_split_datasets.replace(\"~\", path_to_home)\n",
    "path_to_train = os.path.join(path_to_split_datasets, \"train\")\n",
    "path_to_validation = os.path.join(path_to_split_datasets, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tree](images_for_notebook/tree_files.png \"file_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2,\n",
    "                 'Highway': 3, 'Industrial': 4, 'Pasture': 5,\n",
    "                 'PermanentCrop': 6, 'Residential': 7, 'River': 8,\n",
    "                 'SeaLake': 9}\n",
    "num_classes = len(class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg16](images_for_notebook/vgg16.png \"Original VGG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize network model without top layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg16_no_top](images_for_notebook/vgg16_no_top.png \"VGG no top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for CNN\n",
    "if use_vgg:\n",
    "    base_model = VGG(include_top=False,\n",
    "                     weights=None,\n",
    "                     input_shape=(64, 64, 13))\n",
    "else:\n",
    "    base_model = DenseNet(include_top=False,\n",
    "                          weights=None,\n",
    "                          input_shape=(64, 64, 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define new top layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg16_sentinel_rgb](images_for_notebook/vgg16_sentinel_rgb.png \"VGG RGB Sentinel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "top_model = base_model.output\n",
    "top_model = GlobalAveragePooling2D()(top_model)\n",
    "# or just flatten the layers\n",
    "#    top_model = Flatten()(top_model)\n",
    "# let's add a fully-connected layer\n",
    "if use_vgg:\n",
    "    # only in VGG19 a fully connected nn is added for classfication\n",
    "    # DenseNet tends to overfitting if using additionally dense layers\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "# and a logistic layer\n",
    "predictions = Dense(num_classes, activation='softmax')(top_model)\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# print network structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ImageDataGenerators\n",
    "# ... initialization for training\n",
    "training_files = glob(path_to_train + \"/**/*.tif\")\n",
    "train_generator = simple_image_generator(training_files, class_indices,\n",
    "                                         batch_size=batch_size,\n",
    "                                         rotation_range=45,\n",
    "                                         horizontal_flip=True,\n",
    "                                         vertical_flip=True)\n",
    "\n",
    "# ... initialization for validation\n",
    "validation_files = glob(path_to_validation + \"/**/*.tif\")\n",
    "validation_generator = simple_image_generator(validation_files, class_indices,\n",
    "                                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate callback to save best model w.r.t val_categorical_accuracy\n",
    "if use_vgg:\n",
    "    file_name = \"vgg\"\n",
    "else:\n",
    "    file_name = \"dense\"\n",
    "checkpointer = ModelCheckpoint(\"../data/models/\" + file_name +\n",
    "                               \"_ms_from_scratch.\" +\n",
    "                               \"{epoch:02d}-{val_categorical_accuracy:.3f}.\" +\n",
    "                               \"hdf5\",\n",
    "                               monitor='val_categorical_accuracy',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True,\n",
    "                               mode='max')\n",
    "earlystopper = EarlyStopping(monitor='val_categorical_accuracy',\n",
    "                             patience=50,\n",
    "                             mode='max',\n",
    "                             restore_best_weights=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', write_graph=True, write_grads=True,\n",
    "                          write_images=True, update_freq='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorflow](images_for_notebook/tensorflow.png \"VGG RGB Sentinel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 85s 847ms/step - loss: 1.0472 - categorical_accuracy: 0.6573 - val_loss: 1.4713 - val_categorical_accuracy: 0.6851\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.68509, saving model to ../data/models/dense_ms_from_scratch.01-0.685.hdf5\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 49s 491ms/step - loss: 0.6708 - categorical_accuracy: 0.7800 - val_loss: 0.7417 - val_categorical_accuracy: 0.7864\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.68509 to 0.78644, saving model to ../data/models/dense_ms_from_scratch.02-0.786.hdf5\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.5662 - categorical_accuracy: 0.8178 - val_loss: 0.7565 - val_categorical_accuracy: 0.7695\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.78644\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 48s 477ms/step - loss: 0.5295 - categorical_accuracy: 0.8238 - val_loss: 0.4994 - val_categorical_accuracy: 0.8465\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.78644 to 0.84653, saving model to ../data/models/dense_ms_from_scratch.04-0.847.hdf5\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 47s 475ms/step - loss: 0.4575 - categorical_accuracy: 0.8488 - val_loss: 0.5640 - val_categorical_accuracy: 0.8122\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.84653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ac3cb6438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        callbacks=[checkpointer, earlystopper, tensorboard],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
