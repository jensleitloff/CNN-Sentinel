{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note for 02_train_rgb_finetuning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 as VGG\n",
    "from tensorflow.keras.applications.densenet import DenseNet201 as DenseNet\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "from image_functions import preprocessing_image_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define path to training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "path_to_split_datasets = \"~/Documents/Data/PyCon/RGB\"\n",
    "use_vgg = True\n",
    "batch_size = 64\n",
    "\n",
    "# contruct path\n",
    "path_to_home = os.path.expanduser(\"~\")\n",
    "path_to_split_datasets = path_to_split_datasets.replace(\"~\", path_to_home)\n",
    "path_to_train = os.path.join(path_to_split_datasets, \"train\")\n",
    "path_to_validation = os.path.join(path_to_split_datasets, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tree](images_for_notebook/tree_files.png \"file_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine number of classes from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of classes\n",
    "sub_dirs = [sub_dir for sub_dir in os.listdir(path_to_train)\n",
    "            if os.path.isdir(os.path.join(path_to_train, sub_dir))]\n",
    "num_classes = len(sub_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer-learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg16](images_for_notebook/vgg16.png \"Original VGG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pretrained network model without top layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg16_no_top](images_for_notebook/vgg16_no_top.png \"VGG no top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for CNN\n",
    "if use_vgg:\n",
    "    base_model = VGG(include_top=False,\n",
    "                     weights='imagenet',\n",
    "                     input_shape=(64, 64, 3))\n",
    "else:\n",
    "    base_model = DenseNet(include_top=False,\n",
    "                          weights='imagenet',\n",
    "                          input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. define new top layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg16_sentinel_rgb](images_for_notebook/vgg16_sentinel_rgb.png \"VGG RGB Sentinel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "top_model = base_model.output\n",
    "top_model = GlobalAveragePooling2D()(top_model)\n",
    "# or just flatten the layers\n",
    "#    top_model = Flatten()(top_model)\n",
    "# let's add a fully-connected layer\n",
    "if use_vgg:\n",
    "    # only in VGG19 a fully connected nn is added for classfication\n",
    "    # DenseNet tends to overfitting if using additionally dense layers\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "# and a logistic layer\n",
    "predictions = Dense(num_classes, activation='softmax')(top_model)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# print network structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. define data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18900 images belonging to 10 classes.\n",
      "{'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n",
      "Found 8100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# defining ImageDataGenerators\n",
    "# ... initialization for training\n",
    "train_datagen = ImageDataGenerator(fill_mode=\"reflect\",\n",
    "                                   rotation_range=45,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   preprocessing_function=preprocessing_image_rgb)\n",
    "# ... initialization for validation\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocessing_image_rgb)\n",
    "# ... definition for training\n",
    "train_generator = train_datagen.flow_from_directory(path_to_train,\n",
    "                                                    target_size=(64, 64),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "# just for information\n",
    "class_indices = train_generator.class_indices\n",
    "print(class_indices)\n",
    "\n",
    "# ... definition for validation\n",
    "validation_generator = test_datagen.flow_from_directory(path_to_validation,\n",
    "                                                        target_size=(64, 64),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate callback to save best model w.r.t val_categorical_accuracy\n",
    "if use_vgg:\n",
    "    file_name = \"vgg\"\n",
    "else:\n",
    "    file_name = \"dense\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(\"../data/models/\" + file_name +\n",
    "                               \"_rgb_transfer_init.\" +\n",
    "                               \"{epoch:02d}-{val_categorical_accuracy:.3f}.\" +\n",
    "                               \"hdf5\",\n",
    "                               monitor='val_categorical_accuracy',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True,\n",
    "                               mode='max')\n",
    "\n",
    "earlystopper = EarlyStopping(monitor='val_categorical_accuracy',\n",
    "                             patience=10,\n",
    "                             mode='max',\n",
    "                             restore_best_weights=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', write_graph=True, \n",
    "                          write_images=True, update_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorflow](images_for_notebook/tensorflow.png \"VGG RGB Sentinel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. set base layers non trainable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg16_rgb_init](images_for_notebook/vgg16_rgb_init.png \"VGG RGB Sentinel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. fit model (train new top layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.6681 - categorical_accuracy: 0.7841 - val_loss: 0.3120 - val_categorical_accuracy: 0.8931\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.89309, saving model to ../data/models/vgg_rgb_transfer_init.01-0.893.hdf5\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.3477 - categorical_accuracy: 0.8808 - val_loss: 0.2733 - val_categorical_accuracy: 0.9039\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.89309 to 0.90388, saving model to ../data/models/vgg_rgb_transfer_init.02-0.904.hdf5\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.3098 - categorical_accuracy: 0.8961 - val_loss: 0.2515 - val_categorical_accuracy: 0.9126\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.90388 to 0.91263, saving model to ../data/models/vgg_rgb_transfer_init.03-0.913.hdf5\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.2719 - categorical_accuracy: 0.9106 - val_loss: 0.2330 - val_categorical_accuracy: 0.9200\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.91263 to 0.92003, saving model to ../data/models/vgg_rgb_transfer_init.04-0.920.hdf5\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.2601 - categorical_accuracy: 0.9136 - val_loss: 0.3209 - val_categorical_accuracy: 0.8893\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.92003\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=5,\n",
    "                    callbacks=[checkpointer, earlystopper,\n",
    "                               tensorboard],\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=500)\n",
    "initial_epoch = len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. set (some) base layers trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vgg16_rgb_finetune](images_for_notebook/vgg16_rgb_finetune.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "names = []\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print([i, layer.name, layer.trainable])\n",
    "\n",
    "if use_vgg:\n",
    "    # we will freaze the first convolutional block and train all\n",
    "    # remaining blocks, including top layers.\n",
    "    for layer in model.layers[:4]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[4:]:\n",
    "        layer.trainable = True\n",
    "else:\n",
    "    for layer in model.layers[:7]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[7:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. fit model (fine-tune base and top layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.1926 - categorical_accuracy: 0.9299 - val_loss: 0.1883 - val_categorical_accuracy: 0.9356\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from -inf to 0.93564, saving model to ../data/models/vgg_rgb_transfer_final.06-0.936.hdf5\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.1697 - categorical_accuracy: 0.9409 - val_loss: 0.1771 - val_categorical_accuracy: 0.9399\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.93564 to 0.93985, saving model to ../data/models/vgg_rgb_transfer_final.07-0.940.hdf5\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.1614 - categorical_accuracy: 0.9436 - val_loss: 0.1674 - val_categorical_accuracy: 0.9430\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.93985 to 0.94299, saving model to ../data/models/vgg_rgb_transfer_final.08-0.943.hdf5\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.1489 - categorical_accuracy: 0.9515 - val_loss: 0.1619 - val_categorical_accuracy: 0.9466\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.94299 to 0.94663, saving model to ../data/models/vgg_rgb_transfer_final.09-0.947.hdf5\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.1279 - categorical_accuracy: 0.9544 - val_loss: 0.1482 - val_categorical_accuracy: 0.9483\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.94663 to 0.94829, saving model to ../data/models/vgg_rgb_transfer_final.10-0.948.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdff804c978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate callback to save best model w.r.t val_categorical_accuracy\n",
    "if use_vgg:\n",
    "    file_name = \"vgg\"\n",
    "else:\n",
    "    file_name = \"dense\"\n",
    "checkpointer = ModelCheckpoint(\"../data/models/\" + file_name +\n",
    "                               \"_rgb_transfer_final.\" +\n",
    "                               \"{epoch:02d}-{val_categorical_accuracy:.3f}\" +\n",
    "                               \".hdf5\",\n",
    "                               monitor='val_categorical_accuracy',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True,\n",
    "                               mode='max')\n",
    "earlystopper = EarlyStopping(monitor='val_categorical_accuracy',\n",
    "                             patience=50,\n",
    "                             mode='max')\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=100,\n",
    "          epochs=initial_epoch+5,\n",
    "          callbacks=[checkpointer, earlystopper, tensorboard],\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=500,\n",
    "          initial_epoch=initial_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
